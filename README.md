# Multimodal Fake News Detection System  
### Comparing LLMs Across Text + Video Modalities  
**Artificial Intelligence Foundations â€“ ICA 2025**  

---

## ğŸ“Œ Overview  
This project implements a **multimodal fake news detection system** that uses modern Large Language Models (LLMs) to classify *real vs fake* content across text and video modalities.  

The system serves two purposes:

1. **Interactive Artefact**  
   Users can select text or video samples and request predictions from different LLMs.

2. **Evaluation Framework**  
   Enables fair, systematic comparison of multiple LLMs (Gemini, GPT-4o, Mistral) using real datasets:
   - **LIAR dataset** (text)
   - **FaceForensics++ sampled dataset** (video)

This project supports the ICA requirement of developing an implementation *and* conducting a performance evaluation using modern AI techniques.

---

## ğŸ¯ Objectives  

### **A) Functional Artefact**
- Provide an interactive system where users:
  - Browse random fake/real news samples
  - View metadata and extracted frames
  - Choose an LLM
  - Receive a prediction + explanation

### **B) Research/Evaluation Component**
- Compare multiple LLMs on:
  - Fake news classification accuracy
  - Explanation quality
  - Latency (processing time)
  - Performance across modalities (text + video)
- Report findings in ICA submission

---

## ğŸ§  Core Features (Implemented)
- âœ” Clean and scalable backend architecture (Flask + modular packages)  
- âœ” Dynamic frame extraction using OpenCV + FFmpeg  
- âœ” Video metadata integration (~120 curated real/fake samples)  
- âœ” LIAR dataset text loader  
- âœ” Gemini 1.5/2.5 Vision API integrated (fully functional)  
- âœ” API endpoints for:
  - `/api/videos/random`
  - `/api/videos/predict/<id>?model=gemini`
- âœ” Temporary session folder for frame caching  
- âœ” Readable structured JSON output  
- âœ” Extensive testing (`tests/gemini_test.py`)  

---

## ğŸ—ï¸ Project Directory Structure  
```
llms_fake_news_comparison/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ .env
â”œâ”€â”€ llm_venv/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ text/
â”‚   â”‚   â”‚   â””â”€â”€ liar_dataset/
â”‚   â”‚   â”‚       â”œâ”€â”€ train.tsv
â”‚   â”‚   â”‚       â”œâ”€â”€ test.tsv
â”‚   â”‚   â”‚       â”œâ”€â”€ valid.tsv
â”‚   â”‚   â”‚       â””â”€â”€ README
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ video/
â”‚   â”‚       â”œâ”€â”€ faceforensics/
â”‚   â”‚       â”‚   â””â”€â”€ *.mp4
â”‚   â”‚       â”œâ”€â”€ fake_video_metadata.xlsx
â”‚   â”‚       â””â”€â”€ original_video_metadata.xlsx
â”‚   â”‚
â”‚   â”œâ”€â”€ metadata/
â”‚   â”‚   â””â”€â”€ llm_evaluation_metadata.xlsx
â”‚   â”‚
â”‚   â”œâ”€â”€ samples/
â”‚   â”‚   â”œâ”€â”€ cleaned_response.txt
â”‚   â”‚   â””â”€â”€ extracted_text.json
â”‚   â”‚
â”‚   â””â”€â”€ outputs/
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ app.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llms/
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ gemini_wrapper.py
â”‚   â”‚   â”œâ”€â”€ mistral_wrapper.py
â”‚   â”‚   â””â”€â”€ openai_wrapper.py
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ preprocess_video.py
â”‚   â”‚   â””â”€â”€ preprocess_text.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ random_sampler.py
â”‚   â”‚   â”œâ”€â”€ deepfake_loader.py
â”‚   â”‚   â”œâ”€â”€ liar_loader.py
â”‚   â”‚   â”œâ”€â”€ filepaths.py
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â””â”€â”€ helpers.py
â”‚   â”‚
â”‚   â””â”€â”€ temp/
â”‚       â””â”€â”€ frames/
â”‚
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ terminal_client.py
â”‚   â””â”€â”€ client_gui.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ evaluate_models.py
â”‚   â”œâ”€â”€ sample_faceforensics.py
â”‚   â””â”€â”€ extract_frames.sh
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ gemini_test.py
    â””â”€â”€ __init__.py
```

---

## âš™ï¸ Installation

### **1. Clone the repository**
```bash
git clone https://github.com/<your_username>/llms_fake_news_comparison.git
cd llms_fake_news_comparison
```
### **2. Create and activate your own virtual environment**
```bash
python -m venv llm_venv
llm_venv\Scripts\activate  # (Windows)
```
### **3. Install requirements in your own virtual environment**
```bash 
pip install -r requirements.txt
```
### **3. Create and add your models' API keys**
```bash
GEMINI_API_KEY=your_key_here
OPENAI_API_KEY=optional
MISTRAL_API_KEY=optional
```

## ğŸ”¥ Running the Flask Server
```bash
python server/app.py (# server runs on [text](http://127.0.0.1:5000))
```

## ğŸ”Œ API Usage

### ğŸ”¹ Get random videos
#### GET /api/videos/random?batch=10

### ğŸ”¹ Predict fake/real for a specific video
#### GET /api/videos/predict/<video_id>?model=gemini

## ğŸ™ Acknowledgements

Datasets used:

- LIAR Dataset â€” William Wang (2017)

- FaceForensics++ â€” RÃ¶ssler et al. (2019)

LLMs/APIs:

- Google Gemini (Generative AI)

- OpenAI GPT Models

- Mistral AI Models

This project forms part of the coursework for:
Artificial Intelligence Foundations, Semester 2, 2025

## ğŸ“„ License

#### MIT License â€” free for academic use.